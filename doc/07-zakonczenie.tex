\chapter{Podsumowanie i~wnioski\label{chap:zakonczenie}}

Jak napisano we wprowadzeniu do~niniejszej pracy, informatzacja powinna realizować dwa podstawowe cele. Z~jednej strony powinna ona usprawniać pracę pojedynczego pracownika, poprzez automatyzację realizowanych przez niego rutynowych zadań i~obowiązków. Działania jednostki powinny być wykonywane szybciej i~bardziej niezawodnie, dzięki wykorzystaniu możliwości komputerów. Z~drugiej strony informatyzacja powinna również wpływać na~działania całych firm i~instytucji, poprzez wspomaganie procesu podejmowania decyzji przez kadrę zarządzającą przedsiębiorstwami (lub innymi jednostkami). Szybka analiza danych o~stanie firmy może umożliwić podejmowanie trafniejszych decyzji przez kadrę zarządzającą - ma to~duże znaczenie w~przypadku decyzji o~znaczeniu strategicznym dla~rozwoju przedsiębiorstwa.

W chwili obecnej praktycznie w~każdej przestrzeni ludzkiego życia znajduje się~komputer, co~wpłynęło na~produkcję olbrzymich ilości danych. W~większośći są one reprezentowane w~sposób umożliwiający ich łatwe składowanie i~przetwarzanie komputerowe przez aplikacje analityczne. Z~roku na~rok rozmiar danych produkowanych przez różnego rodzaju systemy komputerowe rośnie w~oszałamiającym tempie. Dane te poddane analizie mogą przynieść wymierne korzyści zarówno w~kwestiach finansowych, jak również poznawczych. Dzięki analizie zebranych w~przeszłości informacji możliwe jest lepsze dopasowanie planów w~przyszłości - na~tej podstawie planowane mogą być np. akcje marketingowe, czy~też~promocje w~supermarketach spożywczych. Wiedza uzyskana w~ten sposób może być wykorzystana w~bardzo różnorodnych sytuacjach, praktycznie w~każdym obszarze działalności firmy.

Proces odkrywania zależności pomiędzy zgromadzonymi danymi bez wykorzystania systemów komputerowych jest niezwykle skomplikowany i~wymaga do~realizacji dużo czasu. W~chwili obecnej analiza zgromadzonych danych przez człowieka jest praktycznie niemożliwa, bądź na~tyle powolna, że~wnioski nie~będą przydatne, bo~sytuacja ulegnie zmianie na~tyle, że~informacje z~analizy przestaną być aktualne. Z~tego też powodu tworzone są narzędzia umożliwiające odkrywanie prawidłowości w~dużych zbiorach danych, by człowiek na~tej podstawie mógł podejmować trafne i~szybkie decyzje oraz wyciągać odpowiednie wnioski.

Eksploracja danych jest działem informatyki, który~zajmuje się~poszukiwaniem ukrytych dla~człowieka prawidłowości i~reguł w~danych. Jest to~jeden z~etapów procesu \termdef{odkrywania wiedzy z~baz danych}. Jak~wspomniano we wprowadzeniu, eksploracja danych to~proces poszukiwania wiedzy w~postaci nowych, użytecznych, poprawnych i~zrozumiałych wzorców w~bardzo dużych wolumenach danych~\cite{DataMiningStart}. Możliwości stosowania technik eksploracji danych w~praktyce, wymagają efektywnych metod przeszukiwania ogromnych plików lub~baz danych. Warto przy tym wspomnieć, że~tego typu technologie nie~są w~chwili obecnej dobrze zintegrowane z~systemami zarządzania bazami danych.

Reguły asocjacyjne są jednym z~najczęściej używanych modeli wiedzy w~eksploracji danych. Jak~przedstawiono w~rozdziale~\ref{chap:teoria} reguła asocjacyjna ma postać $X \Rightarrow Y$, gdzie~$X$ oraz~$Y$ są wzajemnie rozłącznymi zbiorami elementów. Przykładem reguły, która~mogła zostać odkryta w~bazie danych sklepu komputerowego, może być reguła postaci $komputer \land myszka \Rightarrow monitor$. Prezentuje ona fakt, że~klienci kupujący komputer oraz myszke, z~dużym prawdopodobieństwem kupią również monitor. Problem odkrywania reguł asocjacyjnych wraz z~algorytmem Apriori, który~jest podstawą wielu algorytmów znajdujących reguły asocjacyjne po raz pierwszy został sformułowany w~\cite{Problem:Statement}. Algorytm ten~następnie rozszerzono w~pracy~\cite{AssRulesStrt} o~bardziej uniwersalne sposoby generowania reguł. Innym rodzajem algorytmu odkrywającego reguły asocjacyjne jest FPGrowth, który~opisany jest w~części~\ref{sec:fpgrowth} niniejszej pracy.

W ostatnich latach pojawiły się~nowe możliwości wykorzystania współczesnych komputerów. W~roku 2007 firma NVIDIA udostępniła programistom uniwersalną architekturę obliczeniową CUDA (\english{Compute Unified Device Architecture}), który~umożliwia wykorzystanie mocy obliczeniowej \termdef{procesorów graficznych} (\acronym{GPU}, \english{Graphics Processing Unit}), bądź innych procesorów wielordzeniowych, do~rozwiązywania ogólnych problemów obliczeniowych w~sposób znacząco wydajniejszy niż w~przypadku tradycyjnych, sekwencyjnych procesorów~\cite{cuda:zone}. W~ramach tworzenia projektu aplikacji porównującej różne algorytmy odkrywające reguły wykorzystana została technologia CUDA, którą~najpierw autor musiał poznać i~w~odpowiedni sposób wykorzystać w~pracy nad implementacją.

Jak do~tej pory bardzo małe jest zainteresowanie wykorzystaniem tej~technologii w~procesie odkrywania wiedzy, a~w~szczególności znajdowania reguł asocjacyjnych. Wyniki przeprowadzonych w ramach tej pracy eksperymentów pozwalają na wyciągnięcie wniosków, że~algorytm wykorzystujący możliwości procesorów wielordzeniowych, po~w~szczególności GPU, będzie wyraźnie szybszy od~klasycznych algorytmów eksploracji danych zaimplementowany na~tradycyjnych procesorach. 

W niniejszej pracy opracowany został algorytm równoległy oparty na~Apriori, który~wykorzystuje możliwości wpółczesnych kart graficznych poprzez wykorzystanie technologii CUDA. Eksperymenty wykazały, że~algorytm ten~jest znacząco szybszy od~innych implemntacji algorytmów z~tej klasy, co~pozwala na~przetworzenie większych zbiorów danych w~tych samych czasach. Z~przeprowadzonych badań jasno wynika również,~że algorytm FPGrowth jest algorytmem wydajniejszym niż~algorytm Apriori, co~może stanowić wskazówkę dla~dalszych prac nad~tematem zrównoleglania algorytmów odkrywających reguły acocjacyjne.

W rozdziale~\ref{chap:eksperymenty} poświęconym eksperymentom zaprezentowano wyniki dla~trzech algorytmów klasy Apriori oraz klasycznego algorytmu FPGrowth. Wydajność tego drugiego znacząco przekraczała wydajności pozostałych algorytmów. W~przyszłości celem jest przyspieszenie algorytmu FPGrowth poprzez zastosowanie technologii CUDA do~zrównoleglenia obliczeń. Dodatkowo potrzebne byłoby przetestowanie algorytmów na~większych zbiorach danych, gdzie odpowiedzi FPGrowth byłyby zależne od~liczby transakcji.