
\chapter{Podstawy teoretyczne}

W rozdziale tym przedstawiony zostanie przegląd literatury, który stanowi podstawy wiedzy na temat eksploracji danych, a w szczególności problemu odkrywania reguł asocjacyjnych w dużych zbiorach danych.

\section{Definicje}

\subsection{Model teoretyczny}

Niech $I = \lbrace i_1,i_2,...,i_m \rbrace$ będzie \emph{zbiorem elementów} o liczności $|I| = m$. \emph{Transakcją} nazwano dowolny, niepusty podzbiór $X \subseteq I$ zbioru elementów. Bazą danych $DB$ nazwano dowolny zbiór par $(id, X)$, gdzie $X$ jest transakcją, a $id$ jest dowolną wartością unikalną w ramach bazy danych nazywaną \emph{identyfikatorem transakcji}. Bez utraty ogólności założono iż $id\in \mathbb{N}$. 

\emph{Wsparciem} (\english{support}) $sup(X)$ transakcji $X$, w bazie danych nazwano częstość wystąpień transakcji w bazie danych. Formalnie przedstawia to wzór~\ref{support:def}.

\begin{equation}
\label{support:def}
sup(X)=\frac{| \lbrace id: (id,Y)\in DB \wedge X\subseteq Y \rbrace |}{|DB|}
\end{equation} 

\begin{df}\label{regula:def}
Niech będą dane dwie transakcje $X$ i $Y$ takie, że $X\cap Y=\emptyset$. Implikację postaci $X\Rightarrow  Y$ nazwano \emph{regułą asocjacyjną}.
\end{df}

Łatwo zauważyć, że jeśli poziom ten jest niski, to oznacza to, że nie ma jednoznacznych dowodów na łączne występowanie elementów zbioru $Z = X \cup Y$, ponieważ zbiór $Z$ występuje w niewielkiej liczbie transakcji. 

\emph{Poziom ufności} (\english{confidence}) jest miarą zdefiniowaną dla implikacji reprezentowanej przez regułę asocjacyjną~\cite{Elmasri:db}. 

\begin{df}\label{confidence:def}
Pioziom ufności ($conf$) reguły asocjacyjnej $X \Rightarrow Y$ jest równy 
\begin{equation}
	conf(X \Rightarrow Y) = \frac{sup(X \cup Y)}{sup(X)}
\end{equation}
\end{df}

Po analizie definicji~\ref{confidence:def} łatwo zauważyć, że poziom ufności może być interpretowany, jako estymacja prawdopodobieństwa $P(Y | X)$.

Reguły asocjacyjne zazwyczaj powinny spełniać pewne wymagania zdefiniowane przez użytkownika - minimalne wsparcie oraz minimalny poziom ufności, oznaczane odpowiednio $minsup$ oraz $minconf$. Wyznaczają one dla aplikacji progi, jakie powinny spełniać zbiory oraz reguł, aby były brane pod uwagę w trakcie analizy.

\begin{df}
Zbiorem częstym $X \subseteq I$ nazywamy taki zbiór, który spełnia zależność $sup(X) \geq minsup$.
\end{df}

Generowanie reguł asocjacyjnych zazwyczaj sprowadza się do dwóch, osobnych kroków:
\begin{enumerate}
	\item Minimalne wsparcie jest używane do odnalezienia wszystkich zbiorów częstych w bazie danych $DB$.
	\item Znalezione zbiory często oraz minimalny poziom ufności są używane do wygenerownia reguł.
\end{enumerate}

Znalezienie wszystkich zbiorów częstych w bazie danych $DB$ jest zadaniem wymagającym przeszukania wszystkich możliwych kombinacji bez powtórzeń ze zbioru $I$. Zbiór możliwych zbiorów elementów ma liczność równą $2^n - 1$ (wszystkie zbiory, poza zbiorem pustym, który nie jest w tym wypadku sensownym zbiorem). 

Warto zauważyć, że dla każdego zbioru częstego $Y$, każdy jego podzbiór $X$ jest również zbiorem częstym~\cite{Problem:Statement}. Korzystając z tej właściwości wsparcia możliwe jest w sposó efektywny znalezienie wszystkich zbiorów częstych w zadanej bazie danyh. Dodatkowo, wszystkie reguły zbudowane na podstawie zbioru częstego $Y$ muszą spełniać warunek minimalnego wsparcia ponieważ spełnia ten warunek zbiór $Y$, a suma zbiorów reguły jest zbiorem wyjściowym $Y$.

\section{Aktualna wiedza}
W rozdziale tym zebrana została oraz opracowana dotychczasowa wiedza (\english{state-of-the-art}) na temat odkrywania reguł asocjacyjnych. Przedstawione zostaną dwa podstawowe algorytmy wykorzystywane w tym procesie: Apriori oraz FP-growth. Na podstawie tych dwóch algorytmów w chwili obecnej budowane są nowe algorytmy, ich modyfikacje wykorzystujące możliwości współczesnych komputerów.

\subsection{Algorytm Apriori}
Pierwszy algorytm odkrywania reguł asocjacyjnych został przedstawiony w roku 1994 w pracy \cite{Apriori:Main}. Niżej przedstawione zostaną szczegóły działania algorytmu \emph{Apriori}.

Zagadnienie odkrywania reguł asocjacyjnych można podzielić na dwa etapy~\cite{Problem:Statement}:
\begin{enumerate}
	\item Generowanie zbiorów częstych, których wartość wsparcia jest wyższa od wartości $minsup$
	\item Generowanie reguł asocjacyjnych na podstawie zbiorów częstych. Reguła $X \Rightarrow Y$ jest wynikiem działania algorytmu, jeżeli spełnia ona nierówność $conf(X \Rightarrow Y) \geq minconf$. Ponieważ zbiór $Z = X \cup Y$ jest zbiorem częstym, to reguła spełnia również warunek przekraczania minimalnego wsparcia.

	Na tym etapie możliwe jest tworzenie reguł, w których w zbiorze \emph{poprzedników} ($X$ z oznaczeń z definicji~\ref{regula:def}) jest wiele elementów~\cite{Problem:Statement} oraz jeden w \emph{następniku} (zbiór $Y$ z definicji~\ref{regula:def}) lub dopuszczana jest możliwość wielu elementów w następniku również~\cite{Apriori:Main}. W niniejszej pracy analizowany jest taki sposób generowania reguł, w którym oba zbiory mogą być zbiorami więcej niż jednoelementowymi.
\end{enumerate}

\subsubsection{Generowanie zbiorów częstych}\label{apriori:gen}
W celu wyznaczenia zbiorów częstych algorytm dokonule analizy bazy danych, by w kolejnych iteracjach generować rodziny coraz to liczniejszych zbiorów, będących zbiorami częstymi dla zadanej wartości $minsup$. Algorytm zaczyna od znalezienia wszystkich zbiorów jednoelementowych, które są zbiorami częstymi. W każdym kolejnym kroku generowane są zbiory częste na podstawie zbiorów wygenerowanych zbiorów w kroku poprzednim. Proces ten jest kontynuowany do momentu aż nie zostaną znalezione żadne zbiory częste.

Algorytm generuje zbiory kandydatów jedynie na podstawie zbiorów częstych odkrytych w kroku poprzednim - co ważne generowanie ich odbywa się bez przeglądania bazy danych transakcji. Intuicja podpowiada, że każdy podzbiór zbioru częstego jest zbiorem częstym. Zatem, każdy zbiór częsty zawierający $k$ elementów może być wygenerowany na podstawie połączenia dwóch zbiorów posiadających $k-1$ elementów, a na koniec kasując te zbiory, których jakikolwiek podzbiór nie jest częsty~\cite{Apriori:Main}.

Procedura \proc{AlgorytmApriori} przedstawia pseudokod realizujący opisywany w tym rozdziale algorytm Apriori.

\begin{codebox}
	\Procname{$\proc{AlgorytmApriori}$}\label{apriori:listing}
	\li $\id{L_1} \gets \lbrace 1$-elementowe zbiory częste $\rbrace$
		\li \For $(k = 2; \id{L_{k-1}} \neq \emptyset; k++)$
		\li \Do
			\li $\id{C_k} \gets aprioriGen(\id{L_{k-1}})$
			\li \textbf{forall} trasakcja $t \in \id{DB}$
			\li \Do
					\li $C_t \gets subset(C_k, t)$
					\li \textbf{forall} kandydat $c \in \id{C_t}$
					\li \Do c.count++
					\End
				\End
			\li $L_k \gets \lbrace c \in C_k | c.count \geq minsup \rbrace$	
		\End
	\li Answer $\gets \bigcup_k L_k $
\end{codebox}

\paragraph{Procedura aprioriGen}
Procedura \id{aprioriGen} reprezentuje proces twórzenia zbiorów $k$-elementowych kandydatów na podstawie zbiorów wejściowych ${k-1}$-elementowych. Procedura ta jest podzielona na dwa etapy: łączenia oraz przycinania. 

Jak łatwo zauważyć wynikiem działania \proc{JoinStep} są zbiory $k$-elementowe, które powstały na podstawie zbiorów wejściowych $L_{k-1}$, a ich zawartość różni się tylko jednym elementem.

\begin{codebox}
	\Procname{$\proc{JoinStep}$}
	\li \textbf{insert into} $C_k$
	\li \textbf{select} p.item$_1$, p.item$_2$, \dots, p.item$_{k-1}$, q.item$_{k-1}$
	\li \textbf{from} $L_{k-1}$ p, $L_{k-1}$ q
	\li \textbf{where} p.item$_1 = $ q.item$_1$, \dots, p.item$_{k-2}$ = q.item$_{k-2}$, p.item$_{k-1}$ $<$ q.item$_{k-1}$
\end{codebox}

Następnym krokiem jest \proc{PruneStep}, w którym usuwane są wszystkie elementy $c \in C_k$, którego jakikolwiek podzbiór $(k-1)$-elementowy zbioru $c$ nie należy do $L_{k-1}$.

\begin{codebox}
	\Procname{$\proc{PruneStep}$}
		\li \textbf{forall} zbiór $c \in C_k$ 
		\li \Do
			\li \textbf{forall} $(k-1)$-elementowy podzbiór s zbioru $c$
					\li \Do 
						\li \If $s \notin L_{k-1}$
						\li \Then
							\li \textbf{delete} $c$ z $C_k$
						\End
					\End
		\End
\end{codebox}

\subsection{Generowanie reguł asocjacyjnych}

Po wyznaczeniu zbiorów częstych algorytm przystępuje do drugiego etapu, czyli do budowania reguł asocjacyjnych na podstawie odkrytych zbiorów. Podobnie, jak w~\cite{Apriori:Main} algorytm będący przedmiotem analizy niniejszej pracy generuje wszystkie możliwe reguły asocjacyjne dla zadanego zbioru. Mniej ogólny sposób generowania reguł został przedstawiony w pracy~\cite{Problem:Statement}, jednakże podjęto decyzję, że jest to sposób zbyt mało użyteczny w środowisku produkcyjnym.

Aby wygenerować reguły, dla każdego zbioru częstego $l$ znajdowane są niepuste podzbiory - podzbiór taki oznaczony jest jako $a$. Dla takich oznaczeń wygenerowna zostanie reguła $a \Rightarrow (l-a)$, jeżeli spełniona jest nierówność $\frac{support(l)}{support(a)} \geq minconr$. Warto zauważyć, że dla każdego zbioru częstego generowane są wszystkie możliwe niepuste podzbiory - zapewnia to, że odkryte zostaną wszystkie możliwe reguły.

%Kluczową własnością wykorzystywaną w tym etapie jest antymonotoniczność funkcji wsparcia:

%Własność Apriori Niech X i Y będą zbiorami towarów. Jeśli X   Y, to 
%support(X)  support(Y)
%Dowód: X  Y  cover(X)  cover(Y)  support(X)  support(Y).

%Rysunek 3: Ilustracja własności Apriori: jeśli AB nie jest częsty, to możemy wykluczyć wszystkie jego nadzbiory
 
%Antymonotoniczność wsparcia ze względu na zawieranie się zbiorów oznacza, że rozszerzenie nieczęstego zbioru nie może prowadzić do częstego zbioru. Jeżeli zatem k-zbiór X nie jest częsty, wówczas możemy pominąć wszystkie zbiory Y, takie że X Í Y (por. rysunek 3).

%Niżej przedstawiamy szczegóły algorytmu, w którym własność Apriori jest wykorzystywana. Analizujemy, jak rodzina k-zbiorów częstych Lk powstaje z k-1 zbiorów częstych Lk-1.

%Dowolny k-zbiór nazywamy kandydatem, jeśli każdy jego (k-1)-podzbiór jest częsty. 

%Łączenie:
%Zakładamy, że towary w bazie transakcyjnej są ponumerowane i wszystkie zbiory są uporządkowane leksykograficznie w rosnącym porządku. Czyli każdy częsty l Î Lk-1 jest reprezentowany jako tablica 
%l = (l[1], l[2],...,l[k-1])
%gdzie l[1] < l[2] < ... < l[k-1]. Operacja łączenia Lk-1  Lk-1 jest wykonywana przez łączenie wszystkich par (k-1)-zbiorów częstych.

%Dwa zbiory l1,l2 Î Lk-1 zostają połączone, jeśli mają one k-2 takich samych elementów na początku, tzn. 
%(l1[1] = l2[1]) Ù (l1[2] = l2[2]) Ù...Ù(l1[k-2] = l2[k-2]) oraz (l1[k-1] < l2[k-1])
%(1)
%Warunek l1[k-1] < l2[k-1] jest po to, aby zapobiegać powstawaniu powtarzających się kandydatów. Wynikiem łączenia zbiorów l1 i l2 spełniających warunek jest k-elementowy zbiór l, który powstaje przez dołączenie l2[k-1] na końcu l1. 

%Przycinanie: Można zauważyć, że powstający zbiór kandydatów Ck jest nadzbiorem zbioru Lk, tzn. że jego elemnety mogą być częste lub nieczęste, ale wszystkie k-zbiory częste należą do Ck. Celem operacji przycinania jest redukowanie rozmiaru zbioru Ck kandydatów przed sprawdzaniem ich wsparcia w bazie transakcji. W tym celu wykorzystujemy własciwość Apriori, z której wynika, że jeśli jakiś (k-1)-podzbiór danego kandydata nie występuje w Lk-1, to ten kandydat powinien być usunięty z Ck. Algorytm sprawdzania obecności podzbiorów kandydatów w Lk-1 może być efektywnie implementowany za pomocą drzewa haszującego dla częstych zbiorów w Lk-1.

\subsection{Algorytm FP-growth}


%Dzięki wykorzystaniu "downward-closure"~\cite{Problem:Statement} właściwości wsparcia, który gwarantuje, że wszystkie podzbiory zbioru częstego, również są zbiorami częstymi (i na odwrót), możliwe jest w sposób efektywny znalezienie wszystkich zbiorów częstych w zadaniej bazie danych.

%While the second step is straight forward, the first step needs more attention.
%Finding all frequent itemsets in a database is difficult since it involves searching all possible itemsets (item combinations). The set of possible itemsets is the power set over I and has size 2n - 1 (excluding the empty set which is not a valid itemset). Although the size of the powerset grows exponentially in the number of items n in I, efficient search is possible using the downward-closure property of support[2][4] (also called anti-monotonicity "Jian Pei, Jiawei Han, and Laks V.S. Lakshmanan. Mining frequent itemsets with convertible constraints. In Proceedings of the 17th International Conference on Data Engineering, April 2–6, 2001, Heidelberg, Germany, pages 433-442, 2001.") which guarantees that for a frequent itemset, all its subsets are also frequent and thus for an infrequent itemset, all its supersets must also be infrequent. Exploiting this property, efficient algorithms (e.g., Apriori[6] and Eclat[7]) can find all frequent itemsets.

%%%%%%%%%%%%%%%%%%%%%%%%%%% GARBAGE!!!

%Z uwagi na fakt, że należy w pewien sposób ograniczyć liczbę reguł, jako wyniku działania algorytmu, wprowadza się dwie wartości $minsup$ oraz $minconf$. Wszystkie kombinacje przedmiotów ($\mathbf{X}_k$), które spełniają nierówność $sup(\mathbf{X}_k) \leq minsup$ nazywane są zbiorami dużymi (LARGE?). Pozostałe zbiory nazywane są zbiorami małymi (SMALL?)~\cite{Problem:Statement}.

%Ze wzoru wynika, że poziom ufności jest estymacją prawdopodobieństwa tego, że elementy tworzące zbiór $\mathbf{Y}$ zostaną kupione przez danego klienta pod warunkiem, że klient kupi elementy należące do zbioru $\mathbf{X}$.

%Inną motywacją, poza statystyczną ważnością, dlaczego interesujący jest poziom pokrycia, jest fakt, że poszukiwane reguły powinny spełniać pewne wymaganie, co do wysokości wartości $sup$ z powodów biznesowych. Jeśli poziom pokrycia nie jest wystarczająco wysoki, to oznacza to, iż reguła nie jest warta brania pod uwagę, bądź jest ona mniej preferowana (może być rozpatrzona później)~\cite{Problem:Statement}. Dlatego też w przypadku reguły asocjacyjnej określenie wartości $sup$ dla każdej reguły i weryfikowanie tylko tych, które spełniają pewne wymagania co do wysokości tego współczynnika.



%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Reguła asocjacyjna zdefiniowana w Definicji~\ref{regula:def} określa, że jeśli dany klient kupił towary ze zbioru $\mathbf{X}$, najprawdopodobniej kupi też towary ze zbioru $\mathbf{Y}$. Aby reguła asocjacyjna stanowiła interesujące źródło informacji dla analityka stosującego techniki eksploracji danych, musi ona spełniać określone warunki wyrażone za pomocą odpowiednich miar. Dwie najbardziej popularne miary jakości reguł asocjacyjnych to poziom pokrycia (\\english{support}) oraz poziom ufności (\english{confidence}).


%Oznacza to, że poziom pokrycia ($sup$) jest stosunkiem liczby transakcji zawierających elementy sumy zbiorów (czyli $|\mathbf{Z}|$, gdzie $\mathbf{Z} = \mathbf{X} \cup \mathbf{Y}$) do liczby wszystkich transakcji w systemie ($|\mathbf{T}|$). Wzór \ref{support2:def} przedstawia sposó obliczania wartości $sup$.

%\begin{equation}\label{support2:def}
	%sup = \frac{|\mathbf{Z}|}{|\mathbf{T}|}
%\end{equation}